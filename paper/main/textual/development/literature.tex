\section{Literature Review}
\label{sec:literature_review}

We performed a simple overview of recent literature regarding distributed reinforcement learning,
and categorized the results according to groups of tags.
This review was made with the purpose of highlighting frequently used algorithms, RL metrics,
and types of system and network benchmarks.
To gather relevant literature, we searched the Web of Science database using the following search query,
while limiting the results to the last 5 years:

\begin{verbatim}
    ALL=(
        (
            "distributed" OR "parallel" OR
            "multi-agent" OR "asynchronous"
        )
        AND
        (
            "shared environments" OR "replay buffer" OR
            "trajectory sampling" OR "experience sampling"
        )
        AND "reinforcement learning"
    )
\end{verbatim}

Initially, a total of 68 papers matched the search query, with 34 being deemed unfit or irrelevant to the
present research question.
The bibliography analysis refeers to the remaining 33, where the tagged categories are as shown:

\begin{itemize}[leftmargin=*, label={--}]
    \item \textbf{Algorithm Categories} (e.g., Q-learning, Actor-Critic, Policy Gradients)
    \item \textbf{Learning Paradigm} (On-Policy, Off-Policy, Model-Free, Model-Based)
    \item \textbf{Communication Model} (Centralized, Decentralized, Asynchronous, Synchronous)
    \item \textbf{RL Metrics} (Reward, Sample Efficiency, Convergence, Stability)
    \item \textbf{System Metrics} (Wall Speed, Latency, Memory, Core Efficiency)
\end{itemize}

