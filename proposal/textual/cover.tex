\title{A Distributed Approach for Reinforcement Learning Agents in High-Frequency Trading}
\author{Rafael Zimmer}
\date{25 de Janeiro de 2025}

   
\maketitle
\begin{abstract}
  High-frequency trading (HFT) demands rapid decision-making and adaptability to dynamic market conditions. 
  Reinforcement learning (RL) has emerged as a promising approach for developing data-driven trading strategies, 
  but existing frameworks often struggle with scalability, latency, and daily updates of trading policies to adequately address changing market conditions.
  This thesis presents a novel distributed approach for an RL framework in the context of agent-based High-Frequency Trading (HFT).
  By introducing a multi-learner design and shared distributed limit order book (LOB) environments, 
  the framework reduces redundant computations and individually simulated environments, achieving high scalability. 
  Key performance metrics such as speedup, multicore efficiency, latency
  and loss and reward scores for trained agents are used to evaluate the framework's effectiveness for HFT applications.
  The proposed architecture aims to allow continuous training and deployment of adaptive agents, 
  and therefore provide a practical approach towards more efficient and robust trading systems.
\end{abstract}


